{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PllMQTvvj3Wb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.linalg import expm\n",
        "import random\n",
        "import math\n",
        "from scipy.stats import unitary_group\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize, curve_fit, basinhopping\n",
        "import matplotlib\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import lightning as L\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "import torch_optimizer\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def set_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    \n",
        "\n",
        "\n",
        "set_random_seed(42)\n",
        "L.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2QloLRRj3Wc",
        "outputId": "770e3fd4-1e0d-4c44-850a-b3e05da70154"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4tLQ7ETj3Wc",
        "outputId": "eaa40d52-78f5-4108-98be-d6020663d0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p1Hrf4k6j3Wd"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for ch in range(4):\n",
        "    for H in range(3):\n",
        "        with open(f\"Calibration Example_915\\ch{ch + 1}_H{H + 1}.txt\") as file:\n",
        "            for line in file:\n",
        "                try:\n",
        "                    row = [float(num) for num in line.split()]\n",
        "                    data.append([H, ch] + row)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "def create_un_mat(v, device):\n",
        "\n",
        "    Mc = torch.zeros((4, 4), dtype=torch.complex128, device=device)\n",
        "\n",
        "    Mc[0, 1] = v[0] + 1j * v[1]\n",
        "    Mc[1, 0] = v[0] - 1j * v[1]\n",
        "\n",
        "    Mc[0, 2] = v[2] + 1j * v[3]\n",
        "    Mc[2, 0] = v[2] - 1j * v[3]\n",
        "\n",
        "    Mc[0, 3] = v[4] + 1j * v[5]\n",
        "    Mc[3, 0] = v[4] - 1j * v[5]\n",
        "\n",
        "    Mc[1, 2] = v[6] + 1j * v[7]\n",
        "    Mc[2, 1] = v[6] - 1j * v[7]\n",
        "\n",
        "    Mc[1, 3] = v[8] + 1j * v[9]\n",
        "    Mc[3, 1] = v[8] - 1j * v[9]\n",
        "\n",
        "    Mc[2, 3] = v[10] + 1j * v[11]\n",
        "    Mc[3, 2] = v[10] - 1j * v[11]\n",
        "\n",
        "    U_torch = torch.matrix_exp(1j * Mc)\n",
        "    return U_torch\n",
        "\n",
        "def f(v, data):\n",
        "\n",
        "    M1 = create_un_mat(v[:12], device=device)\n",
        "    M2 = create_un_mat(v[12:24], device=device)\n",
        "\n",
        "    alpha = v[24:33].reshape(3, 3)\n",
        "    h_0 = v[33:36]\n",
        "    cost = torch.tensor(0.0, dtype=torch.float32, device=device)\n",
        "\n",
        "    for i in data:\n",
        "        x = torch.zeros(3, dtype=torch.float32, device=device)\n",
        "        x[i[0]] = 10**(-5) * i[2] ** 2\n",
        "        y = torch.tensor(i[3:], dtype=torch.complex128, device=device)\n",
        "        y /= torch.sum(y)\n",
        "\n",
        "        h_list = h_0 + alpha @ x\n",
        "        H_diag = torch.cat([\n",
        "            torch.exp(1j * h_list),\n",
        "            torch.tensor([1.0], dtype=torch.complex128, device=device)\n",
        "        ])\n",
        "        H = torch.diag(H_diag)\n",
        "        predict = torch.abs((M2 @ H @ M1).T) ** 2\n",
        "        cost += torch.norm(predict[i[1]] - y)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlB1eI66j3Wd",
        "outputId": "ca424b04-994e-43d3-840d-18ddf794a833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([ 0.1940,  2.1614, -0.1721,  0.8491, -1.9244,  0.6530, -0.6494, -0.8175,\n",
            "         0.5280, -1.2753, -1.6621, -0.3033, -0.0926,  0.1992, -1.1204,  1.8577,\n",
            "        -0.7145,  0.6881,  0.7968, -0.0334,  1.4917, -0.5165, -0.2541,  1.4746,\n",
            "        -0.3260, -1.1600,  2.3551, -0.6924,  0.1837, -1.1835, -1.8029, -1.5808,\n",
            "         0.8387,  1.4192,  0.6469,  0.4253], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "x0 = nn.Parameter(torch.randn(36, dtype=torch.float32, device=device), requires_grad=True)\n",
        "# optimizer = optim.Adam([x0], lr=0.3)\n",
        "optimizer = torch_optimizer.Adahessian([x0], lr=0.3, weight_decay=1e-5, betas=(0.9, 0.999), eps=1e-8)\n",
        "# U = create_un_mat(x0, device=device)\n",
        "scheduler = CosineAnnealingLR(optimizer_x0, T_max=100)\n",
        "\n",
        "print(x0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.1940,  2.1614, -0.1721,  0.8491, -1.9244,  0.6530, -0.6494, -0.8175,\n",
            "         0.5280, -1.2753, -1.6621, -0.3033, -0.0926,  0.1992, -1.1204,  1.8577,\n",
            "        -0.7145,  0.6881,  0.7968, -0.0334,  1.4917, -0.5165, -0.2541,  1.4746,\n",
            "        -0.3260, -1.1600,  2.3551, -0.6924,  0.1837, -1.1835, -1.8029, -1.5808,\n",
            "         0.8387,  1.4192,  0.6469,  0.4253], device='cuda:0',\n",
            "       grad_fn=<CloneBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x0_optimized = x0.clone()\n",
        "print(x0_optimized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/ex1 --port 6008"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Enhqywj3Wd",
        "outputId": "20363a64-2a58-4449-a2ca-b879a1c1465e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1/100\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Gradient tensor 0 does not have grad_fn. When calling loss.backward(), make sure the option create_graph is set to True.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [9], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#  print(x0.grad)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nikab\\anaconda3\\envs\\torch-v2\\lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nikab\\anaconda3\\envs\\torch-v2\\lib\\site-packages\\torch_optimizer\\adahessian.py:158\u001b[0m, in \u001b[0;36mAdahessian.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    154\u001b[0m             grads\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# get the Hessian diagonal\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m hut_traces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (p, group, grad, hut_trace) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    161\u001b[0m     params, groups, grads, hut_traces\n\u001b[0;32m    162\u001b[0m ):\n\u001b[0;32m    164\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate[p]\n",
            "File \u001b[1;32mc:\\Users\\nikab\\anaconda3\\envs\\torch-v2\\lib\\site-packages\\torch_optimizer\\adahessian.py:98\u001b[0m, in \u001b[0;36mAdahessian.get_trace\u001b[1;34m(self, params, grads)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradient tensor \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m does not have grad_fn. When \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalling loss.backward(), make sure the option \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     96\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_graph is set to True.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     97\u001b[0m         )\n\u001b[1;32m---> 98\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m    100\u001b[0m v \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint_like(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params\n\u001b[0;32m    107\u001b[0m ]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# this is for distributed setting with single node and multi-gpus,\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# for multi nodes setting, we have not support it yet.\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Gradient tensor 0 does not have grad_fn. When calling loss.backward(), make sure the option create_graph is set to True."
          ]
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "min_loss = 1e10\n",
        "steps = 100\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "lr_range = np.logspace(1, 0.1, 10)\n",
        "T_max_range = np.linspace(10, 10000, 10)\n",
        "\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    loss = f(x0, data)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(x0, max_norm=1.0)\n",
        "    # print(f\"loss: {loss.item()}\")\n",
        "    if loss.item() < 1e-5:\n",
        "        print(\"Converged\")\n",
        "    return loss\n",
        "\n",
        "# for lr in lr_range:\n",
        "#     for T_max in T_max_range:\n",
        "\n",
        "# run_id = datetime.now().strftime(f\"lr={lr}_Tmax={T_max}\")\n",
        "run_id = datetime.now().strftime(f\"lr=0.3_weight_decay=1e-5_betas=(0.9, 0.999)_eps=1e-8\")\n",
        "log_dir = os.path.join(\"logs\", \"ex1\", run_id)\n",
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "# optimizer = optim.Adam([x0], lr=lr)\n",
        "# scheduler = CosineAnnealingLR(optimizer, T_max=T_max)\n",
        "\n",
        "for n in range(steps):\n",
        "    print(f\"Step {n + 1}/{steps}\")\n",
        "    optimizer.step(closure)\n",
        "    scheduler.step()\n",
        "    #  print(x0.grad)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loss = f(x0, data)\n",
        "        writer.add_scalar(\"Loss/train\", loss.item(), n)\n",
        "        writer.add_scalar(\"Learning rate\", scheduler.get_last_lr()[0], n)\n",
        "    \n",
        "    #  if n % 100 == 0:  # Every 100 steps\n",
        "    #     with torch.no_grad():\n",
        "    #         perturbation = torch.randn_like(x0) * 0.01  # Small random noise\n",
        "    #         x0.add_(perturbation)\n",
        "    #         print(f\"Applied random perturbation at step {n + 1}\")\n",
        "\n",
        "    #  print(f\"Epoch {n+1}: Learning rate = {current_lr:.6f}\")\n",
        "    if n == steps - 1:\n",
        "        print(\"Final loss:\", closure().item())\n",
        "        print(\"Final parameters:\", x0.data.cpu().numpy())\n",
        "        if loss.item() < min_loss:\n",
        "            min_loss = loss.item()\n",
        "            x0_optimized = x0.clone()\n",
        "            print(\"Updated optimized parameters\")\n",
        "        x0 = nn.Parameter(torch.randn(36, dtype=torch.float32, device=device), requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer.close()\n",
        "\n",
        "import shutil\n",
        "shutil.rmtree(\"logs/ex1\", ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAl2SrbSj3Wd"
      },
      "outputs": [],
      "source": [
        "print(x0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hrf-PYIrj3Wd",
        "outputId": "61502a7d-9fbc-4e3c-ede1-dbc894596cdc"
      },
      "outputs": [],
      "source": [
        "M1 = create_un_mat(x0[:12], device=device)\n",
        "M2 = create_un_mat(x0[12:24], device=device)\n",
        "alpha = torch.tensor(x0[24:33], dtype=torch.complex128, device=device).reshape(3, 3)\n",
        "h_0 = torch.tensor(x0[33:36], dtype=torch.complex128, device=device)\n",
        "\n",
        "fig, ax = plt.subplots(3, 4, figsize=(16, 10))\n",
        "\n",
        "for j in range(12):\n",
        "\n",
        "    for i in data[131*j:131*(j+1)]:\n",
        "        x = torch.zeros(3, dtype=torch.complex128, device=device)\n",
        "        x[i[0]] = 10**(-5) * i[2] ** 2\n",
        "        y = torch.tensor(i[3:], dtype=torch.complex128, device=device)\n",
        "        y /= torch.sum(y)\n",
        "\n",
        "        h_list = h_0 + alpha @ x\n",
        "        H_diag = torch.cat([torch.exp(1j * h_list), torch.tensor([1.0], dtype=torch.complex64, device=device)])\n",
        "        H = torch.diag(H_diag)\n",
        "        result = (torch.abs((M2 @ H @ M1).T) ** 2)[i[1]]\n",
        "        ax[j//4][j%4].scatter(i[2], result[0].cpu().detach().numpy(), color = 'blue')\n",
        "        ax[j//4][j%4].scatter(i[2], result[1].cpu().detach().numpy(), color = 'green')\n",
        "        ax[j//4][j%4].scatter(i[2], result[2].cpu().detach().numpy(), color = 'yellow')\n",
        "        ax[j//4][j%4].scatter(i[2], result[3].cpu().detach().numpy(), color = 'red')\n",
        "\n",
        "    ax[j//4][j%4].plot([d[2] for d in data[131*j:131*(j+1)]], [d[3]/sum(d[3:]) for d in data[131*j:131*(j+1)]])#, color = 'blue')\n",
        "    ax[j//4][j%4].plot([d[2] for d in data[131*j:131*(j+1)]], [d[4]/sum(d[3:]) for d in data[131*j:131*(j+1)]])#, color = 'green')\n",
        "    ax[j//4][j%4].plot([d[2] for d in data[131*j:131*(j+1)]], [d[5]/sum(d[3:]) for d in data[131*j:131*(j+1)]])#, color = 'yellow')\n",
        "    ax[j//4][j%4].plot([d[2] for d in data[131*j:131*(j+1)]], [d[6]/sum(d[3:]) for d in data[131*j:131*(j+1)]])#, color = 'red')\n",
        "\n",
        "    ax[0][0].set_xlabel('Сила тока, единицы')\n",
        "    ax[0][0].set_ylabel('Выходное излучение (норм)')\n",
        "\n",
        "    fig.suptitle('Фитирование данных Ильи с помощью нашего кода')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VQlbVsdj3We"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch-v2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
